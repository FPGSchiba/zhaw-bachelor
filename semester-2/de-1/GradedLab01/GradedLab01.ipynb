{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering 1: Graded Lab 01\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grading\n",
    "For this graded lab you can get a total of 10 points. These 10 points count 10% of your final grade for the course.\n",
    "\n",
    "#### Start\n",
    "Start of the Graded Lab 01 is **Thursday, March 21st at 23:55**.\n",
    "\n",
    "#### Deadline\n",
    "Deadline for the submission of the Graded Lab 01 is **Thursday, April 11th at 23:59**.\n",
    "\n",
    "#### Note\n",
    "Check each result carefully. Use data filter, cleaning, and transformation methods wherever needed. The data can sometimes be really messy and have hidden issues.\n",
    "\n",
    "#### Submission\n",
    "You are allowed to submit the solution in groups of **two or three** students.\n",
    "Submit your GradedLab01.ipynb file renamed to FirstnameStudent01LastnameStudent01_FirstnameStudent02LastnameStudent02_FirstnameStudent03LastnameStudent03.ipynb in moodle.   \n",
    "Please submit a runnable python jupyter notebook file.\n",
    "All other submissions will be rejected and graded with 0 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 01: Structured Data [4 points].    \n",
    "The imdb.csv file contains a dataset extracted from IMDB with several attributes. For example, the title, plot, and the language of the movies. Read the imdb.csv file in a pandas dataframe and try to answer the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __(a)  What is the min, max, and the average value of the attribute 'rating' for all movies? [0.5 points].__ "
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "!pip install pandas"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T15:00:15.806050Z",
     "start_time": "2024-04-01T15:00:15.792550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 8.1\n",
      "Max: 9.6\n",
      "Average: 8.6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('imdb.csv')\n",
    "\n",
    "data.head()\n",
    "\n",
    "print(f\"Min: {data.rating.min()}\")\n",
    "print(f\"Max: {data.rating.max()}\")\n",
    "print(f\"Average: {data.rating.mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __(b) What is the min, max, and the average value of the attribute 'cumulative worldwide gross' for all movies? [0.5 points].__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T15:00:17.303957Z",
     "start_time": "2024-04-01T15:00:17.289432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.0\n",
      "Max: 2797800564.0\n",
      "Average: 238223230.2\n"
     ]
    }
   ],
   "source": [
    "data[\"cumulative worldwide gross\"] = data[\"cumulative worldwide gross\"].str.replace(r'\\s.+', '', regex=True).replace(r'\\D', '', regex=True).astype(float)\n",
    "\n",
    "print(f\"Min: {data['cumulative worldwide gross'].min()}\")\n",
    "print(f\"Max: {data['cumulative worldwide gross'].max()}\")\n",
    "print(f\"Average: {data['cumulative worldwide gross'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __(c) What is the min, max, and the average value of the attribute 'cumulative worldwide gross' grouped by genre of the movies? [1 point].__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T15:00:18.649195Z",
     "start_time": "2024-04-01T15:00:18.627696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "genres\nAction         4.655257e+08\nAdventure      5.123588e+08\nAnimation      3.958353e+08\nBiography      1.538608e+08\nComedy         2.447827e+08\nCrime          1.824480e+08\nDocumentary    0.000000e+00\nDrama          2.290571e+08\nFamily         5.497713e+08\nFantasy        3.426368e+08\nGame-Show      0.000000e+00\nHistory        7.840920e+07\nHorror         8.982547e+07\nMusic          2.946962e+08\nMusical        6.325005e+08\nMystery        1.406539e+08\nNews           0.000000e+00\nReality-TV     0.000000e+00\nRomance        2.344835e+08\nSci-Fi         4.410689e+08\nSport          1.164948e+08\nTalk-Show      0.000000e+00\nThriller       2.154442e+08\nWar            1.213808e+08\nWestern        3.362419e+08\nName: cumulative worldwide gross, dtype: float64"
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['genres'] = data['genres'].apply(lambda x: x.replace(\"'\", '').strip('][').split(', ') if not isinstance(x, list) else x)\n",
    "data = data.explode('genres')\n",
    "data.groupby(by=['genres'], dropna=True)['cumulative worldwide gross'].min()\n",
    "data.groupby(by=['genres'], dropna=True)['cumulative worldwide gross'].max()\n",
    "data.groupby(by=['genres'], dropna=True)['cumulative worldwide gross'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __(d) What is the profit (defined as cumulative worldwide gross - budget) of each movie? [1 point].__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T15:00:20.597263Z",
     "start_time": "2024-04-01T15:00:20.585232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0       33500000.0\n1      239066411.0\n1      239066411.0\n2      819558444.0\n2      819558444.0\n          ...     \n156            0.0\n156            0.0\n157            0.0\n157            0.0\n158            0.0\nLength: 487, dtype: float64"
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.budget = data.budget.str.replace(r'\\D', '', regex=True).astype(float)\n",
    "profit = data['cumulative worldwide gross'] - data.budget\n",
    "profit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __(e)  What is the min, max, and the average value of the atttribute 'opening weekend united states' per month? [1 point].__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T15:01:49.128113Z",
     "start_time": "2024-04-01T15:01:49.106118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "opening weekend united states dates\n1.0     1.326144e+07\n2.0     2.974682e+07\n3.0     3.421716e+07\n4.0     1.593046e+08\n5.0     5.929679e+07\n6.0     5.916076e+07\n7.0     5.430706e+07\n8.0     1.121913e+07\n9.0     1.056989e+07\n10.0    2.193238e+07\n11.0    2.672944e+07\n12.0    1.964329e+07\nName: opening weekend united states income, dtype: float64"
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "data['opening weekend united states']= data['opening weekend united states'].apply(lambda x: x.replace(\"$\", '').split(', ') if not isinstance(x, list) else x)\n",
    "data = data.merge(data['opening weekend united states'].apply(lambda s: pd.Series({'opening weekend united states income': float(s[0].replace(',', '')), 'opening weekend united states dates': datetime.datetime.strptime(s[1], '%d %b %Y')}) if len(s) > 1 else pd.Series({'opening weekend united states income': np.NaN, 'opening weekend united states dates': np.NaN})), left_index=True, right_index=True)\n",
    "\n",
    "data.groupby(by=[data['opening weekend united states dates'].dt.month], dropna=True)['opening weekend united states income'].min()\n",
    "data.groupby(by=[data['opening weekend united states dates'].dt.month], dropna=True)['opening weekend united states income'].max()\n",
    "data.groupby(by=[data['opening weekend united states dates'].dt.month], dropna=True)['opening weekend united states income'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 02: Unstructured Data [6 points]. \n",
    "This time use the files imdb.csv from Task 01 and the imdb2.csv file. In this task we mainly use the content of the attribute 'plot' for the implementation of a retrieval system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __(a)  Read the files imdb.csv and imdb2.csv in a dataframe called imdb. Add a column which is called 'plotterms' to each item. The new column should contain all terms (lower-case and cleaned from special characters) from the plot attribute which are not contained in the stopwords_english.txt file. [0.5 points]__ "
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "     - -------------------------------------- 0.5/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     --- ------------------------------------ 1.2/12.8 MB 6.8 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 2.1/12.8 MB 9.7 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 12.9 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 5.3/12.8 MB 16.8 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 7.8/12.8 MB 21.7 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 11.4/12.8 MB 43.5 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 50.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.6)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.24.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.14.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jann\\.conda\\envs\\zhaw\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.7.1\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!spacy download en_core_web_sm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T15:27:04.201989Z",
     "start_time": "2024-04-01T15:26:58.170182Z"
    }
   },
   "execution_count": 204
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T15:35:09.046198Z",
     "start_time": "2024-04-01T15:35:04.434071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "           id       kind                           title  \\\n0      120669      movie  Fear and Loathing in Las Vegas   \n1     1343092      movie                The Great Gatsby   \n2     2069861      movie               My Favorite Movie   \n3     2267368      movie                     Joshua Tree   \n4    13560124      movie                   After America   \n..        ...        ...                             ...   \n154   2085059  tv series                    Black Mirror   \n155   2707408  tv series                          Narcos   \n156     98936  tv series                      Twin Peaks   \n157   4934214  tv series                      Taskmaster   \n158    200276  tv series                   The West Wing   \n\n                                             languages  \\\n0                                          ['English']   \n1                                          ['English']   \n2                                          ['English']   \n3                                          ['English']   \n4                                ['English', 'Somali']   \n..                                                 ...   \n154                                        ['English']   \n155                             ['English', 'Spanish']   \n156  ['English', 'Icelandic', 'Afrikaans', 'Norwegi...   \n157                                        ['English']   \n158                                        ['English']   \n\n                                          genres  rating       director  \\\n0               ['Adventure', 'Comedy', 'Drama']     7.5  Terry Gilliam   \n1                           ['Drama', 'Romance']     7.2   Baz Luhrmann   \n2                           ['Comedy', 'Family']     8.4  Martin Rogers   \n3                                      ['Drama']     6.6       Li Cheng   \n4                ['Drama', 'Fantasy', 'Mystery']     4.5     Jake Yuzna   \n..                                           ...     ...            ...   \n154   ['Drama', 'Mystery', 'Sci-Fi', 'Thriller']     8.8            NaN   \n155  ['Biography', 'Crime', 'Drama', 'Thriller']     8.8            NaN   \n156    ['Crime', 'Drama', 'Mystery', 'Thriller']     8.8            NaN   \n157                      ['Comedy', 'Game-Show']     9.0            NaN   \n158                                    ['Drama']     8.9            NaN   \n\n    cumulative worldwide gross opening weekend united states     budget  \\\n0                            0                             0          0   \n1                            0                             0          0   \n2                            0                             0          0   \n3                            0                             0          0   \n4                            0                             0          0   \n..                         ...                           ...        ...   \n154                  000000000                     000000000  000000000   \n155                  000000000                     000000000  000000000   \n156                  000000000                     000000000  000000000   \n157                  000000000                     000000000  000000000   \n158                  000000000                     000000000  000000000   \n\n                                                  plot  \\\n0    An oddball journalist and his psychopathic law...   \n1    A writer and wall street trader. Nick. finds h...   \n2    Dave has the American Dream and hates it His e...   \n3    Set in the US heartland following the 2008 eco...   \n4    A group of criminal justice deescalation worke...   \n..                                                 ...   \n154  An anthology series exploring a twisted. hight...   \n155  A chronicled look at the criminal exploits of ...   \n156  An idiosyncratic FBI agent investigates the mu...   \n157  Five comedians are set tasks challenging their...   \n158  Inside the lives of staffers in the West Wing ...   \n\n                                             plotterms  \n0    [an, oddball, journalist, and, his, psychopath...  \n1    [a, writer, and, wall, street, trader, ., nick...  \n2    [dave, has, the, american, dream, and, hates, ...  \n3    [set, in, the, us, heartland, following, the, ...  \n4    [a, group, of, criminal, justice, deescalation...  \n..                                                 ...  \n154  [an, anthology, series, exploring, a, twisted,...  \n155  [a, chronicled, look, at, the, criminal, explo...  \n156  [an, idiosyncratic, fbi, agent, investigates, ...  \n157  [five, comedians, are, set, tasks, challenging...  \n158  [inside, the, lives, of, staffers, in, the, we...  \n\n[167 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>kind</th>\n      <th>title</th>\n      <th>languages</th>\n      <th>genres</th>\n      <th>rating</th>\n      <th>director</th>\n      <th>cumulative worldwide gross</th>\n      <th>opening weekend united states</th>\n      <th>budget</th>\n      <th>plot</th>\n      <th>plotterms</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>120669</td>\n      <td>movie</td>\n      <td>Fear and Loathing in Las Vegas</td>\n      <td>['English']</td>\n      <td>['Adventure', 'Comedy', 'Drama']</td>\n      <td>7.5</td>\n      <td>Terry Gilliam</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>An oddball journalist and his psychopathic law...</td>\n      <td>[an, oddball, journalist, and, his, psychopath...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1343092</td>\n      <td>movie</td>\n      <td>The Great Gatsby</td>\n      <td>['English']</td>\n      <td>['Drama', 'Romance']</td>\n      <td>7.2</td>\n      <td>Baz Luhrmann</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>A writer and wall street trader. Nick. finds h...</td>\n      <td>[a, writer, and, wall, street, trader, ., nick...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2069861</td>\n      <td>movie</td>\n      <td>My Favorite Movie</td>\n      <td>['English']</td>\n      <td>['Comedy', 'Family']</td>\n      <td>8.4</td>\n      <td>Martin Rogers</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Dave has the American Dream and hates it His e...</td>\n      <td>[dave, has, the, american, dream, and, hates, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2267368</td>\n      <td>movie</td>\n      <td>Joshua Tree</td>\n      <td>['English']</td>\n      <td>['Drama']</td>\n      <td>6.6</td>\n      <td>Li Cheng</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Set in the US heartland following the 2008 eco...</td>\n      <td>[set, in, the, us, heartland, following, the, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13560124</td>\n      <td>movie</td>\n      <td>After America</td>\n      <td>['English', 'Somali']</td>\n      <td>['Drama', 'Fantasy', 'Mystery']</td>\n      <td>4.5</td>\n      <td>Jake Yuzna</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>A group of criminal justice deescalation worke...</td>\n      <td>[a, group, of, criminal, justice, deescalation...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>154</th>\n      <td>2085059</td>\n      <td>tv series</td>\n      <td>Black Mirror</td>\n      <td>['English']</td>\n      <td>['Drama', 'Mystery', 'Sci-Fi', 'Thriller']</td>\n      <td>8.8</td>\n      <td>NaN</td>\n      <td>000000000</td>\n      <td>000000000</td>\n      <td>000000000</td>\n      <td>An anthology series exploring a twisted. hight...</td>\n      <td>[an, anthology, series, exploring, a, twisted,...</td>\n    </tr>\n    <tr>\n      <th>155</th>\n      <td>2707408</td>\n      <td>tv series</td>\n      <td>Narcos</td>\n      <td>['English', 'Spanish']</td>\n      <td>['Biography', 'Crime', 'Drama', 'Thriller']</td>\n      <td>8.8</td>\n      <td>NaN</td>\n      <td>000000000</td>\n      <td>000000000</td>\n      <td>000000000</td>\n      <td>A chronicled look at the criminal exploits of ...</td>\n      <td>[a, chronicled, look, at, the, criminal, explo...</td>\n    </tr>\n    <tr>\n      <th>156</th>\n      <td>98936</td>\n      <td>tv series</td>\n      <td>Twin Peaks</td>\n      <td>['English', 'Icelandic', 'Afrikaans', 'Norwegi...</td>\n      <td>['Crime', 'Drama', 'Mystery', 'Thriller']</td>\n      <td>8.8</td>\n      <td>NaN</td>\n      <td>000000000</td>\n      <td>000000000</td>\n      <td>000000000</td>\n      <td>An idiosyncratic FBI agent investigates the mu...</td>\n      <td>[an, idiosyncratic, fbi, agent, investigates, ...</td>\n    </tr>\n    <tr>\n      <th>157</th>\n      <td>4934214</td>\n      <td>tv series</td>\n      <td>Taskmaster</td>\n      <td>['English']</td>\n      <td>['Comedy', 'Game-Show']</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>000000000</td>\n      <td>000000000</td>\n      <td>000000000</td>\n      <td>Five comedians are set tasks challenging their...</td>\n      <td>[five, comedians, are, set, tasks, challenging...</td>\n    </tr>\n    <tr>\n      <th>158</th>\n      <td>200276</td>\n      <td>tv series</td>\n      <td>The West Wing</td>\n      <td>['English']</td>\n      <td>['Drama']</td>\n      <td>8.9</td>\n      <td>NaN</td>\n      <td>000000000</td>\n      <td>000000000</td>\n      <td>000000000</td>\n      <td>Inside the lives of staffers in the West Wing ...</td>\n      <td>[inside, the, lives, of, staffers, in, the, we...</td>\n    </tr>\n  </tbody>\n</table>\n<p>167 rows Ã— 12 columns</p>\n</div>"
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "data = pd.read_csv('imdb2.csv')\n",
    "imdb = pd.read_csv('imdb.csv')\n",
    "\n",
    "imdb = pd.concat([data, imdb])\n",
    "\n",
    "with open('stopwords_english.txt', 'r+', encoding='utf-8') as file:\n",
    "    stopwords = file.readlines()\n",
    "\n",
    "def tokenize(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.text.lower() for token in doc if token.text not in stopwords]\n",
    "\n",
    "imdb['plot'] = imdb['plot'].apply(lambda x: '. '.join([re.sub(r'[^\\w\\s]', '', y) for y in x.split(', ')]))\n",
    "imdb['plotterms'] = imdb['plot'].apply(tokenize)\n",
    "imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __(b)  Create an inverted index for the terms in the 'plotterms' column. Use a datastructure of your choice for the implementation [0.5 points]__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T15:35:11.656601Z",
     "start_time": "2024-04-01T15:35:11.616054Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'an': 0,\n 'oddball': 1,\n 'journalist': 2,\n 'and': 3,\n 'his': 4,\n 'psychopathic': 5,\n 'lawyer': 6,\n 'travel': 7,\n 'to': 8,\n 'las': 9,\n 'vegas': 10,\n 'for': 11,\n 'a': 12,\n 'series': 13,\n 'of': 14,\n 'psychedelic': 15,\n 'escapades': 16,\n '.': 17,\n 'the': 18,\n 'bigscreen': 19,\n 'version': 20,\n 'hunter': 21,\n 's': 22,\n 'thompsons': 23,\n 'seminal': 24,\n 'classic': 25,\n 'about': 26,\n 'road': 27,\n 'trip': 28,\n 'across': 29,\n 'western': 30,\n 'america': 31,\n 'as': 32,\n 'he': 33,\n 'large': 34,\n 'samoan': 35,\n 'searched': 36,\n 'desperately': 37,\n 'american': 38,\n 'dream': 39,\n 'they': 40,\n 'were': 41,\n 'helped': 42,\n 'in': 43,\n 'part': 44,\n 'by': 45,\n 'huge': 46,\n 'amount': 47,\n 'drugs': 48,\n 'alcohol': 49,\n 'kept': 50,\n 'their': 51,\n 'convertible': 52,\n 'red': 53,\n 'sharklaurence': 54,\n 'mixson': 55,\n 'raoul': 56,\n 'duke': 57,\n 'is': 58,\n 'drug': 59,\n 'addled': 60,\n 'gonzo': 61,\n 'sent': 62,\n 'cover': 63,\n 'motorcycle': 64,\n 'race': 65,\n 'article': 66,\n 'magazine': 67,\n 'but': 68,\n 'then': 69,\n 'situation': 70,\n 'escalates': 71,\n 'into': 72,\n 'him': 73,\n 'psychotic': 74,\n 'attorney': 75,\n 'searching': 76,\n 'aided': 77,\n 'almost': 78,\n 'every': 79,\n 'known': 80,\n 'man': 81,\n 'boot': 82,\n 'convertiblepalmtreehead': 83,\n 'adaptation': 84,\n 'novel': 85,\n 'same': 86,\n 'name': 87,\n 'film': 88,\n 'details': 89,\n 'whacky': 90,\n 'search': 91,\n 'thompson': 92,\n 'crazed': 93,\n 'fueled': 94,\n 'massive': 95,\n 'purchased': 96,\n 'with': 97,\n 'advance': 98,\n 'from': 99,\n 'sporting': 100,\n 'event': 101,\n 'set': 102,\n 'out': 103,\n 'shark': 104,\n 'encountering': 105,\n 'police': 106,\n 'reporters': 107,\n 'gamblers': 108,\n 'racers': 109,\n 'hitchhikers': 110,\n 'some': 111,\n 'undefinable': 112,\n 'thing': 113,\n 'know': 114,\n 'only': 115,\n 'find': 116,\n 'fear': 117,\n 'loathing': 118,\n 'hilarious': 119,\n 'adventures': 120,\n 'dementia': 121,\n 'modern': 122,\n 'westj': 123,\n 'd': 124,\n 'keith': 125,\n 'jkeithcompunetnet': 126,\n 'writer': 127,\n 'wall': 128,\n 'street': 129,\n 'trader': 130,\n 'nick': 131,\n 'finds': 132,\n 'himself': 133,\n 'drawn': 134,\n 'past': 135,\n 'lifestyle': 136,\n 'millionaire': 137,\n 'neighbor': 138,\n 'jay': 139,\n 'gatsby': 140,\n 'f': 141,\n 'scott': 142,\n 'fitzgeralds': 143,\n 'long': 144,\n 'islandset': 145,\n 'where': 146,\n 'midwesterner': 147,\n 'carraway': 148,\n 'lured': 149,\n 'lavish': 150,\n 'world': 151,\n 'soon': 152,\n 'enough': 153,\n 'however': 154,\n 'will': 155,\n 'see': 156,\n 'through': 157,\n 'cracks': 158,\n 'gatsbys': 159,\n 'nouveau': 160,\n 'riche': 161,\n 'existence': 162,\n 'obsession': 163,\n 'madness': 164,\n 'tragedy': 165,\n 'awaitanonymous': 166,\n 'new': 167,\n 'york1929': 168,\n 'bondseller': 169,\n 'sanitarium': 170,\n 'depression': 171,\n 'alcoholism': 172,\n 'persuaded': 173,\n 'doctor': 174,\n 'write': 175,\n 'therapeutic': 176,\n 'account': 177,\n 'what': 178,\n 'put': 179,\n 'there': 180,\n 'nicks': 181,\n 'journal': 182,\n 'describes': 183,\n 'how': 184,\n 'seven': 185,\n 'years': 186,\n 'earlier': 187,\n 'had': 188,\n 'moved': 189,\n 'tiny': 190,\n 'house': 191,\n 'on': 192,\n 'island': 193,\n 'adjoining': 194,\n 'sumptuous': 195,\n 'mansion': 196,\n 'owned': 197,\n 'enigmatic': 198,\n 'neighbour': 199,\n 'fabulously': 200,\n 'wealthy': 201,\n 'after': 202,\n 'attending': 203,\n 'one': 204,\n 'legendary': 205,\n 'parties': 206,\n 'asked': 207,\n 'arrange': 208,\n 'meeting': 209,\n 'cousin': 210,\n 'daisy': 211,\n 'now': 212,\n 'married': 213,\n 'brutish': 214,\n 'philandering': 215,\n 'tom': 216,\n 'buchanan': 217,\n 'who': 218,\n 'was': 219,\n 'true': 220,\n 'love': 221,\n 'prior': 222,\n 'war': 223,\n 'service': 224,\n 'complies': 225,\n 'comes': 226,\n 'that': 227,\n 'once': 228,\n 'poor': 229,\n 'boy': 230,\n 'has': 231,\n 'recreated': 232,\n 'fascinating': 233,\n 'purely': 234,\n 'win': 235,\n 'back': 236,\n 'events': 237,\n 'drunken': 238,\n 'afternoon': 239,\n 'conspire': 240,\n 'bring': 241,\n 'ending': 242,\n 'which': 243,\n 'anything': 244,\n 'happydon': 245,\n ' ': 246,\n 'minifie1': 247,\n 'midwest': 248,\n 'native': 249,\n 'arrives': 250,\n '1922': 251,\n 'york': 252,\n 'wouldbe': 253,\n 'moves': 254,\n 'nextdoor': 255,\n 'bay': 256,\n 'her': 257,\n 'husband': 258,\n 'joel': 259,\n 'edgerton': 260,\n 'thus': 261,\n 'becomes': 262,\n 'captivating': 263,\n 'bears': 264,\n 'witness': 265,\n 'illusions': 266,\n 'deceits': 267,\n 'pens': 268,\n 'tale': 269,\n 'impossible': 270,\n 'dreams': 271,\n 'tragedyjwelch5742': 272,\n 'its': 273,\n 'spring': 274,\n 'wideeyed': 275,\n 'tobey': 276,\n 'maguire': 277,\n 'just': 278,\n 'city': 279,\n 'pursuit': 280,\n 'settling': 281,\n 'home': 282,\n 'next': 283,\n 'door': 284,\n 'leonardo': 285,\n 'dicaprio': 286,\n 'grows': 287,\n 'increasingly': 288,\n 'fascinated': 289,\n 'elaborate': 290,\n 'held': 291,\n 'at': 292,\n 'neighbors': 293,\n 'estate': 294,\n 'meanwhile': 295,\n 'carraways': 296,\n 'carey': 297,\n 'mulligan': 298,\n 'flounders': 299,\n 'marriage': 300,\n 'aristocrat': 301,\n 'inspired': 302,\n 'debauchery': 303,\n 'display': 304,\n 'wild': 305,\n 'lives': 306,\n 'elite': 307,\n 'begins': 308,\n 'putting': 309,\n 'pen': 310,\n 'paper': 311,\n 'it': 312,\n 'gradually': 313,\n 'clear': 314,\n 'share': 315,\n 'complicated': 316,\n 'romantic': 317,\n 'remains': 318,\n 'unresolved': 319,\n 'decadence': 320,\n 'ebullience': 321,\n 'awaits': 322,\n 'innocent': 323,\n 'aspiring': 324,\n 'cinematic': 325,\n 'great': 326,\n 'little': 327,\n 'cottage': 328,\n 'during': 329,\n 'roaring': 330,\n 'twenties': 331,\n 'elusive': 332,\n 'instead': 333,\n 'humble': 334,\n 'strikes': 335,\n 'acquaintance': 336,\n 'mysterious': 337,\n 'selfmade': 338,\n 'whose': 339,\n 'extravagant': 340,\n 'bacchanalian': 341,\n 'gatherings': 342,\n 'are': 343,\n 'talk': 344,\n 'west': 345,\n 'egg': 346,\n 'instantly': 347,\n 'fabulous': 348,\n 'dazzling': 349,\n 'nouveauriche': 350,\n 'entangled': 351,\n 'jays': 352,\n 'triangle': 353,\n 'unrequited': 354,\n 'passion': 355,\n 'formers': 356,\n 'overpowering': 357,\n 'impulses': 358,\n 'fervent': 359,\n 'desires': 360,\n 'pave': 361,\n 'way': 362,\n 'bitter': 363,\n 'heartbreak': 364,\n 'bloodsoaked': 365,\n 'all': 366,\n 'fleeting': 367,\n 'illusionnick': 368,\n 'riganas': 369,\n 'ambitious': 370,\n 'stockbroker': 371,\n 'befriended': 372,\n 'named': 373,\n 'beguiled': 374,\n 'first': 375,\n 'glitz': 376,\n 'glamour': 377,\n 'surroundings': 378,\n 'surprising': 379,\n 'chain': 380,\n 'lead': 381,\n 'become': 382,\n 'utterly': 383,\n 'repelled': 384,\n 'wreckless': 385,\n 'behaviour': 386,\n 'questionable': 387,\n 'moralsbecksykane': 388,\n 'dave': 389,\n 'hates': 390,\n 'eccentric': 391,\n 'friends': 392,\n 'quite': 393,\n 'happy': 394,\n 'bizarre': 395,\n 'life': 396,\n 'struggle': 397,\n 'pull': 398,\n 'depressed': 399,\n 'darkness': 400,\n 'wants': 401,\n 'everyone': 402,\n 'young': 403,\n 'pushover': 404,\n 'bookworm': 405,\n 'grew': 406,\n 'up': 407,\n 'good': 408,\n 'grades': 409,\n 'received': 410,\n 'college': 411,\n 'degree': 412,\n 'works': 413,\n 'cubicle': 414,\n 'daves': 415,\n 'best': 416,\n 'gas': 417,\n 'station': 418,\n 'workers': 419,\n 'video': 420,\n 'game': 421,\n 'addicated': 422,\n 'secretareis': 423,\n 'stock': 424,\n 'brokers': 425,\n 'hate': 426,\n 'evil': 427,\n 'fast': 428,\n 'food': 429,\n 'mcducks': 430,\n 'corporate': 431,\n 'quests': 432,\n 'help': 433,\n 'happiness': 434,\n 'trouble': 435,\n 'arises': 436,\n 'when': 437,\n 'falls': 438,\n 'employee': 439,\n 'must': 440,\n 'keep': 441,\n 'knowing': 442,\n 'found': 443,\n 'within': 444,\n 'walls': 445,\n 'most': 446,\n 'hated': 447,\n 'entity': 448,\n 'while': 449,\n 'fighting': 450,\n 'darknessmartin': 451,\n 'rogers': 452,\n 'us': 453,\n 'heartland': 454,\n 'following': 455,\n '2008': 456,\n 'economic': 457,\n 'collapse': 458,\n 'recently': 459,\n 'divorced': 460,\n 'suburban': 461,\n 'mother': 462,\n 'two': 463,\n 'girls': 464,\n 'struggles': 465,\n 'hold': 466,\n 'onto': 467,\n 'usa': 468,\n 'facing': 469,\n 'foreclosure': 470,\n 'inhibited': 471,\n 'dysfunctional': 472,\n 'family': 473,\n 'she': 474,\n 'few': 475,\n 'opportunities': 476,\n 'connections': 477,\n 'work': 478,\n 'community': 479,\n 'laid': 480,\n 'bare': 481,\n 'father': 482,\n 'patriarch': 483,\n 'faces': 484,\n 'especially': 485,\n 'painful': 486,\n 'redemptionanonymous': 487,\n 'group': 488,\n 'criminal': 489,\n 'justice': 490,\n 'deescalation': 491,\n 'minneapolis': 492,\n 'embark': 493,\n 'collaborative': 494,\n 'project': 495,\n 'uses': 496,\n 'radical': 497,\n 'workshop': 498,\n 'techniques': 499,\n 'explore': 500,\n 'reallife': 501,\n 'escape': 502,\n 'pressures': 503,\n '2019': 504,\n 'embarked': 505,\n 'used': 506,\n 'theater': 507,\n 'result': 508,\n 'finished': 509,\n 'days': 510,\n 'before': 511,\n 'murder': 512,\n 'george': 513,\n 'floyd': 514,\n 'captures': 515,\n 'lies': 516,\n 'nightmare': 517,\n 'undocumented': 518,\n 'day': 519,\n 'laborers': 520,\n 'hired': 521,\n 'couple': 522,\n 'expect': 523,\n 'be': 524,\n 'biggest': 525,\n 'payday': 526,\n 'turns': 527,\n 'terrifying': 528,\n 'fight': 529,\n 'survival': 530,\n 'beneath': 531,\n 'played': 532,\n 'lynn': 533,\n 'collins': 534,\n 'james': 535,\n 'tupper': 536,\n 'hope': 537,\n 'couples': 538,\n 'secluded': 539,\n 'those': 540,\n 'thought': 541,\n 'helpless': 542,\n 'prove': 543,\n 'ca': 544,\n 'nt': 545,\n 'discarded': 546,\n 'so': 547,\n 'easily': 548,\n 'coming': 549,\n 'age': 550,\n 'story': 551,\n 'russian': 552,\n 'immigrant': 553,\n 'daanyik': 554,\n 'nine': 555,\n 'yearold': 556,\n 'immigrates': 557,\n 'united': 558,\n 'states': 559,\n 'late': 560,\n 'nineteenseventies': 561,\n 'pursue': 562,\n 'daanyiks': 563,\n 'childhood': 564,\n 'pencil': 565,\n 'drawings': 566,\n 'toy': 567,\n 'soldier': 568,\n 'battles': 569,\n 'moscow': 570,\n 'interrupted': 571,\n 'overnight': 572,\n 'hurled': 573,\n 'harsh': 574,\n 'reality': 575,\n 'adulthood': 576,\n 'upon': 577,\n 'losing': 578,\n 'deema': 579,\n 'meela': 580,\n 'left': 581,\n 'alone': 582,\n 'foreign': 583,\n 'land': 584,\n 'desperation': 585,\n 'relationship': 586,\n 'tolik': 587,\n 'abusive': 588,\n 'may': 589,\n 'have': 590,\n 'hand': 591,\n 'deemas': 592,\n 'death': 593,\n 'trapped': 594,\n 'precarious': 595,\n 'web': 596,\n 'torment': 597,\n 'brought': 598,\n 'stepfather': 599,\n 'lecherous': 600,\n 'rabbi': 601,\n 'neighborhood': 602,\n 'bully': 603,\n 'drawing': 604,\n 'source': 605,\n 'comfort': 606,\n 'catharsis': 607,\n 'grow': 608,\n 'fiercer': 609,\n 'tender': 610,\n 'overcome': 611,\n 'insurmountable': 612,\n 'odds': 613,\n 'save': 614,\n 'complete': 615,\n 'destructionanonymous': 616,\n 'promise': 617,\n 'jancsi': 618,\n 'major': 619,\n 'move': 620,\n 'whirlwind': 621,\n 'budapest': 622,\n 'arrival': 623,\n 'immediately': 624,\n 'step': 625,\n 'mirage': 626,\n 'wealth': 627,\n 'opportunity': 628,\n 'themselves': 629,\n 'outskirts': 630,\n 'packed': 631,\n 'grandpa': 632,\n 'jenos': 633,\n 'doublewide': 634,\n 'trailer': 635,\n 'assimilate': 636,\n 'facetoface': 637,\n 'bonds': 638,\n 'them': 639,\n 'together': 640,\n 'forces': 641,\n 'try': 642,\n 'push': 643,\n 'apart': 644,\n 'end': 645,\n 'we': 646,\n 'men': 647,\n 'never': 648,\n 'truly': 649,\n 'behind': 650,\n 'women': 651,\n 'continue': 652,\n 'cultivate': 653,\n 'plight': 654,\n 'proves': 655,\n 'universal': 656,\n 'truth': 657,\n 'greatest': 658,\n 'obstacles': 659,\n 'achieving': 660,\n 'personal': 661,\n 'lie': 662,\n 'ourselves': 663,\n 'chronicles': 664,\n 'experiences': 665,\n 'formerly': 666,\n 'successful': 667,\n 'banker': 668,\n 'prisoner': 669,\n 'gloomy': 670,\n 'jailhouse': 671,\n 'shawshank': 672,\n 'being': 673,\n 'guilty': 674,\n 'crime': 675,\n 'did': 676,\n 'not': 677,\n 'commit': 678,\n 'portrays': 679,\n 'mans': 680,\n 'unique': 681,\n 'dealing': 682,\n 'torturous': 683,\n 'along': 684,\n 'befriends': 685,\n 'number': 686,\n 'fellow': 687,\n 'prisoners': 688,\n 'notably': 689,\n 'wise': 690,\n 'longterm': 691,\n 'inmate': 692,\n 'godfather': 693,\n 'don': 694,\n 'vito': 695,\n 'corleone': 696,\n 'head': 697,\n 'mafia': 698,\n 'daughters': 699,\n 'wedding': 700,\n 'michael': 701,\n 'vitos': 702,\n 'youngest': 703,\n 'son': 704,\n 'decorated': 705,\n 'ww': 706,\n 'ii': 707,\n 'marine': 708,\n 'also': 709,\n 'present': 710,\n 'seems': 711,\n 'uninterested': 712,\n 'business': 713,\n 'powerful': 714,\n 'kind': 715,\n 'give': 716,\n 'respect': 717,\n 'ruthless': 718,\n 'against': 719,\n 'do': 720,\n 'treacherous': 721,\n 'rival': 722,\n 'sell': 723,\n 'needs': 724,\n 'dons': 725,\n 'influence': 726,\n 'refuses': 727,\n 'follows': 728,\n 'clash': 729,\n 'between': 730,\n 'fading': 731,\n 'old': 732,\n 'values': 733,\n 'ways': 734,\n 'cause': 735,\n 'reluctant': 736,\n 'doing': 737,\n 'wage': 738,\n 'mob': 739,\n 'other': 740,\n 'families': 741,\n 'could': 742,\n 'tear': 743,\n 'year': 744,\n 'batman': 745,\n '2005': 746,\n 'lieutenant': 747,\n 'gordon': 748,\n 'district': 749,\n 'harvey': 750,\n 'dent': 751,\n 'successfully': 752,\n 'begin': 753,\n 'round': 754,\n 'criminals': 755,\n 'plague': 756,\n 'gotham': 757,\n 'until': 758,\n 'sadistic': 759,\n 'mastermind': 760,\n 'joker': 761,\n 'appears': 762,\n 'creating': 763,\n 'wave': 764,\n 'chaos': 765,\n 'batmans': 766,\n 'deeply': 767,\n 'forcing': 768,\n 'confront': 769,\n 'everything': 770,\n 'believes': 771,\n 'improve': 772,\n 'technology': 773,\n 'stop': 774,\n 'develops': 775,\n 'bruce': 776,\n 'wayne': 777,\n 'rachel': 778,\n 'dawes': 779,\n 'oskar': 780,\n 'schindler': 781,\n 'vain': 782,\n 'greedy': 783,\n 'german': 784,\n 'businessman': 785,\n 'unlikely': 786,\n 'humanitarian': 787,\n 'amid': 788,\n 'barbaric': 789,\n 'nazi': 790,\n 'reign': 791,\n 'feels': 792,\n 'compelled': 793,\n 'turn': 794,\n 'factory': 795,\n 'refuge': 796,\n 'jews': 797,\n 'based': 798,\n 'managed': 799,\n '1100': 800,\n 'gassed': 801,\n 'auschwitz': 802,\n 'concentration': 803,\n 'camp': 804,\n 'testament': 805,\n 'jules': 806,\n 'winnfield': 807,\n 'samuel': 808,\n 'l': 809,\n 'jackson': 810,\n 'vincent': 811,\n 'vega': 812,\n 'john': 813,\n 'travolta': 814,\n 'hit': 815,\n 'retrieve': 816,\n 'suitcase': 817,\n 'stolen': 818,\n 'employer': 819,\n 'boss': 820,\n 'marsellus': 821,\n 'wallace': 822,\n 'ving': 823,\n 'rhames': 824,\n 'take': 825,\n 'wife': 826,\n 'mia': 827,\n 'uma': 828,\n 'thurman': 829,\n 'later': 830,\n 'town': 831,\n 'butch': 832,\n 'coolidge': 833,\n 'willis': 834,\n 'aging': 835,\n 'boxer': 836,\n 'paid': 837,\n 'lose': 838,\n 'these': 839,\n 'seemingly': 840,\n 'unrelated': 841,\n 'people': 842,\n 'woven': 843,\n 'comprising': 844,\n 'funny': 845,\n 'uncalledfor': 846,\n 'incidents': 847,\n 'forrest': 848,\n 'gump': 849,\n 'simple': 850,\n 'low': 851,\n 'iq': 852,\n 'intentions': 853,\n 'running': 854,\n 'friend': 855,\n 'jenny': 856,\n 'mama': 857,\n 'teaches': 858,\n 'leaves': 859,\n 'choose': 860,\n 'destiny': 861,\n 'joins': 862,\n 'army': 863,\n 'vietnam': 864,\n 'finding': 865,\n 'called': 866,\n 'dan': 867,\n 'bubba': 868,\n 'wins': 869,\n 'medals': 870,\n 'creates': 871,\n 'famous': 872,\n 'shrimp': 873,\n 'fishing': 874,\n 'fleet': 875,\n 'inspires': 876,\n 'jog': 877,\n 'starts': 878,\n 'pingpong': 879,\n 'craze': 880,\n 'smiley': 881,\n 'writes': 882,\n 'bumper': 883,\n 'stickers': 884,\n 'songs': 885,\n 'donates': 886,\n 'meets': 887,\n 'president': 888,\n 'several': 889,\n 'times': 890,\n 'this': 891,\n 'irrelevant': 892,\n 'can': 893,\n 'think': 894,\n 'sweetheart': 895,\n 'curran': 896,\n 'messed': 897,\n 'although': 898,\n 'anyone': 899,\n 'nameless': 900,\n 'person': 901,\n 'narrator': 902,\n 'edward': 903,\n 'norton': 904,\n 'attends': 905,\n 'support': 906,\n 'groups': 907,\n 'attempt': 908,\n 'subdue': 909,\n 'emotional': 910,\n 'state': 911,\n 'relieve': 912,\n 'insomniac': 913,\n 'marla': 914,\n 'helena': 915,\n 'bonham': 916,\n 'carter': 917,\n 'another': 918,\n 'fake': 919,\n 'attendee': 920,\n 'more': 921,\n 'bearable': 922,\n 'associates': 923,\n 'tyler': 924,\n 'brad': 925,\n 'pitt': 926,\n 'dragged': 927,\n 'underground': 928,\n 'club': 929,\n 'soap': 930,\n 'making': 931,\n 'scheme': 932,\n 'spiral': 933,\n 'control': 934,\n 'engage': 935,\n 'competitive': 936,\n 'rivalry': 937,\n 'power': 938,\n 'dom': 939,\n 'cobb': 940,\n 'skilled': 941,\n 'thief': 942,\n 'absolute': 943,\n 'dangerous': 944,\n 'art': 945,\n 'extraction': 946,\n 'stealing': 947,\n 'valuable': 948,\n 'secrets': 949,\n 'deep': 950,\n 'subconscious': 951,\n 'mind': 952,\n 'vulnerable': 953,\n 'cobbs': 954,\n 'rare': 955,\n 'ability': 956,\n 'made': 957,\n 'coveted': 958,\n 'player': 959,\n 'espionage': 960,\n 'international': 961,\n 'fugitive': 962,\n 'cost': 963,\n 'ever': 964,\n 'loved': 965,\n 'offered': 966,\n 'chance': 967,\n 'redemption': 968,\n 'last': 969,\n 'job': 970,\n 'if': 971,\n 'accomplish': 972,\n 'inception': 973,\n 'perfect': 974,\n 'heist': 975,\n 'team': 976,\n 'specialists': 977,\n 'off': 978,\n 'reverse': 979,\n 'task': 980,\n 'steal': 981,\n 'idea': 982,\n 'plant': 983,\n 'succeed': 984,\n 'no': 985,\n 'careful': 986,\n 'planning': 987,\n 'or': 988,\n 'expertise': 989,\n 'prepare': 990,\n 'enemy': 991,\n 'predict': 992,\n 'seen': 993,\n 'luke': 994,\n 'skywalker': 995,\n 'han': 996,\n 'solo': 997,\n 'princess': 998,\n 'leia': 999,\n ...}"
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = {}\n",
    "count = 0\n",
    "\n",
    "def append_index(plotterms):\n",
    "    for term in plotterms:\n",
    "        if index.get(term) is None:\n",
    "            index[term] = len(index)\n",
    "imdb['plotterms'].apply(append_index)\n",
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __(c) Take the inverted index and create the posting list for the query 'american'. Return the posting list as well as the top5 items scored by the rating attribute. [0.5 points]__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __(d) Take the inverted index and create the posting lists for the query terms 'american' and 'dream' (the term 'american' as well as the term 'dream' should be contained in the plot). Your merging algorithm should be efficient and reduce the number of comparison to a minimum. Don't use existing python methods (like intersect or in) for the merge algorithm. Return the merged posting list as well as the top5 items scored by the rating attribute. [1 point]__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __(e) Extend your index to be able to rank the resulting items from Task 2d by the occurrence of search terms in the plotterms. Execute the query 'american' and 'dream' (the term 'american' as well as the term 'dream' should be contained in the plot) again and print the resulting items.  [1 point]__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __(f) Use the TF-IDF score and the cosine similarity to execute the query 'american' and 'dream' (the term 'american' as well as the term 'dream' should be contained in the plot) against all plots in the collection. Print the results with the corresponding ranking score. Also execute the query 'american' or 'dream' (the term 'american' or the term 'dream' should be contained in the plot).  [1.5 points]__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
